{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fac963",
   "metadata": {},
   "source": [
    "[Control] Analysis of the results\n",
    "--------\n",
    "\n",
    "This notebook focuses on the analysis of the properties for the control setting.\n",
    "In particular, when generating sentences from diferent models with different decoding algorithms:\n",
    "\n",
    "- How do different properties of the model change?\n",
    "- Do we obtain multimodal distributions?\n",
    "- Does the 10-th or 90-th percentile analysis tells a different story than the average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1755256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.color_palette(\"colorblind\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9af54",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "This version of the code is limited to processing a single sample (i.e., sampled with a single seed for the same decoding configuration). Bootstrap-like analysis are not being considered in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c2e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Global constants setup: User should update these variables\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "MODEL = \"EleutherAI__pythia-1.4b\" \n",
    "\n",
    "DECODING_SETUP = [\n",
    "    \"multinomial\",\n",
    "    (\"temperature\", (0.1, 0.3, 0.5, 1.15, 1.5)),\n",
    "    (\"top_k\", (2, 10, 40, 100)),\n",
    "    (\"top_p\", (0.1, 0.3, 0.5, 0.7, 0.8, 0.9)),\n",
    "]\n",
    "\n",
    "RESULTS_DIR = \"/extra/ucinlp1/cbelem/experiment-ro-prompts/generations-results/uncond\"\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "def get_filenames(base_dir: str, model: str, decoding_configs: List) -> List[str]:\n",
    "    \"\"\"Compute all filenames for a given model and decoding configs.\"\"\"\n",
    "    def parse_decoding_algo(dec):\n",
    "        if isinstance(dec, str):\n",
    "            return [dec]\n",
    "        \n",
    "        elif isinstance(dec, tuple) and len(dec) == 2:\n",
    "            if dec[0] ==\"temperature\":\n",
    "                return [f\"temperature_{d}\" for d in dec[1]]\n",
    "            if dec[0] ==\"top_p\":\n",
    "                return [f\"top_p_{p}\" for p in dec[1]]\n",
    "            if dec[0] ==\"top_k\":\n",
    "                return [f\"top_k_{k}\" for k in dec[1]]\n",
    "        else:\n",
    "            raise ValueError(f\"Decoding config unknown: {dec}\")\n",
    "            \n",
    "    decodings = []\n",
    "    filepaths = []\n",
    "    \n",
    "    for configs in decoding_configs:\n",
    "        for config in parse_decoding_algo(configs):\n",
    "            fp = f\"{base_dir}/{model}/{config}.csv\"\n",
    "            \n",
    "            if os.path.isfile(fp):\n",
    "                decodings.append(config)\n",
    "                filepaths.append(fp)\n",
    "            else:\n",
    "                print(\"FileNotFound:\\n-->\", fp)\n",
    "                \n",
    "    return decodings, filepaths\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Read files\n",
    "# --------------------------------------------------\n",
    "decodings, filepaths = get_filenames(RESULTS_DIR, MODEL, DECODING_SETUP)\n",
    "files = [pd.read_csv(fp, index_col=0) for fp in filepaths]\n",
    "\n",
    "# Discriminate between different decodings\n",
    "all_files = {\"temp\": [], \"top_p\": [], \"top_k\": []}\n",
    "\n",
    "for file, decoding in zip(files, decodings):\n",
    "    file.insert(0, \"decoding\", decoding)\n",
    "    \n",
    "    if decoding == \"multinomial\":\n",
    "        all_files[\"temp\"].append(file)\n",
    "        all_files[\"top_p\"].append(file)\n",
    "        all_files[\"top_k\"].append(file)\n",
    "    elif decoding.startswith(\"temperature\"):\n",
    "        all_files[\"temp\"].append(file)\n",
    "    elif decoding.startswith(\"top_k\"):\n",
    "        all_files[\"top_k\"].append(file)\n",
    "    elif decoding.startswith(\"top_p\"):\n",
    "        all_files[\"top_p\"].append(file)\n",
    "    \n",
    "# all_files: mapping decoding_algo --> dataframe\n",
    "all_files = {dec: pd.concat(dec_files, axis=0) for dec, dec_files in all_files.items()}\n",
    "# all_files concatenated\n",
    "all_files_concat = pd.concat(files, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc9d34",
   "metadata": {},
   "source": [
    "## Properties distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f12d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PALETTE = sns.color_palette(\"colorblind\", n_colors=1)\n",
    "\n",
    "# fixme - hard coded decoding groupings\n",
    "TEMP_DECODINGS = ['temperature_0.1', 'temperature_0.3', 'temperature_0.5', 'temperature_1.15', 'temperature_1.5']\n",
    "TOPK_DECODINGS = ['top_k_2', 'top_k_10', 'top_k_40', 'top_k_100']\n",
    "TOPP_DECODINGS = ['top_p_0.1', 'top_p_0.3', 'top_p_0.5', 'top_p_0.7', 'top_p_0.8', 'top_p_0.9']\n",
    "\n",
    "TEMP_PALETTE = sns.color_palette(\"Greens\", n_colors=len(TEMP_DECODINGS))\n",
    "TOPK_PALETTE = sns.color_palette(\"Blues\", n_colors=len(TOPK_DECODINGS))\n",
    "TOPP_PALETTE = sns.color_palette(\"Reds\", n_colors=len(TOPP_DECODINGS))\n",
    "\n",
    "DEFAULT_COLORS = {\n",
    "    \"temp\": {c: TEMP_PALETTE[i] for i, c in enumerate(TEMP_DECODINGS)},\n",
    "    \"top_p\": {c: TOPP_PALETTE[i] for i, c in enumerate(TOPP_DECODINGS)},\n",
    "    \"top_k\": {c: TOPK_PALETTE[i] for i, c in enumerate(TOPK_DECODINGS)},\n",
    "}\n",
    "DEFAULT_COLORS[\"temp\"][\"multinomial\"] = DEFAULT_PALETTE[0]\n",
    "DEFAULT_COLORS[\"top_p\"][\"multinomial\"] = DEFAULT_PALETTE[0]\n",
    "DEFAULT_COLORS[\"top_k\"][\"multinomial\"] = DEFAULT_PALETTE[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302bca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avgs(data: pd.DataFrame, property1: str, colname: str) -> tuple:\n",
    "    avgs = data[[colname, property1]].groupby(colname).mean()[property1]\n",
    "    dec, dec_avg = zip(*avgs.items())\n",
    "    # returns the name of the decoding algorithm and its\n",
    "    # decoding_avg\n",
    "    return dec, dec_avg\n",
    "\n",
    "\n",
    "def plot_histograms(property1, figsize=(20, 6), **kwargs):\n",
    "    fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=figsize)\n",
    "    fig.suptitle(f\"{property1} distribution\")\n",
    "    hist_kwargs = dict(hue=\"decoding\", x=property1, element=\"poly\", alpha=0.3, stat=\"probability\")\n",
    "    hist_kwargs.update(**kwargs)\n",
    "    for i, decode_alg in enumerate((\"temp\", \"top_p\", \"top_k\")):\n",
    "        data, palette = all_files[decode_alg], DEFAULT_COLORS[decode_alg]\n",
    "\n",
    "        axes[i].set_title(decode_alg)\n",
    "        ax = sns.histplot(data, palette=palette, ax=axes[i], **hist_kwargs)\n",
    "            \n",
    "        dec_algs, dec_avgs = compute_avgs(data, property1, \"decoding\")\n",
    "        for alg, avg in zip(dec_algs, dec_avgs):\n",
    "            ax.axvline(avg, label=alg, color=palette[alg], ls=\"--\")\n",
    "            \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(property1=\"sequence_log_prob\", binwidth=10) # must normalize size of the properties\n",
    "plt.show()\n",
    "plot_histograms(property1=\"sequence_log_prob\", binwidth=10) # must normalize size of the properties\n",
    "plt.xlim(-400, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735867f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(property1=\"num_chars\", binwidth=50)\n",
    "plt.show()\n",
    "plot_histograms(property1=\"num_chars\", binwidth=50)\n",
    "plt.xlim(0, 650)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(property1=\"num_sentences\", binwidth=1)\n",
    "plt.show()\n",
    "plot_histograms(property1=\"num_sentences\", binwidth=1)\n",
    "plt.xlim(0, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(property1=\"num_punct\", binwidth=5)\n",
    "plt.show()\n",
    "plot_histograms(property1=\"num_punct\", binwidth=1)\n",
    "plt.xlim(0, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(property1=\"num_words\", binwidth=5)\n",
    "plt.show()\n",
    "plot_histograms(property1=\"num_words\", binwidth=2)\n",
    "plt.xlim(0, 125)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be32726",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(property1=\"diversity\", binwidth=0.025)\n",
    "plt.show()\n",
    "plot_histograms(property1=\"diversity\", binwidth=0.025)\n",
    "plt.xlim(0.15, 0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3797e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(property1=\"toxicity\", binwidth=0.02)\n",
    "plt.show()\n",
    "plot_histograms(property1=\"toxicity\", binwidth=0.02)\n",
    "plt.ylim(0, 0.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cce37e",
   "metadata": {},
   "source": [
    "## Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from quantiles import quantile_intervals\n",
    "from collections import defaultdict\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "QUANTILES = [0.1, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "QUANTILES_CI_CONFIDENCE = 0.95\n",
    "\n",
    "# Sanity check\n",
    "r = quantile_intervals(len(files[0]), QUANTILES, desired_confidence=QUANTILES_CI_CONFIDENCE)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0][\"toxicity\"].sort_values().values[r[\"desired_ranks\"].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6348d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quantiles(\n",
    "        decodings,\n",
    "        files,\n",
    "        properties=[\"toxicity\", \"diversity\", \"num_sentences\", \"sequence_log_prob\"],\n",
    "        quantiles=QUANTILES,\n",
    "        conf=QUANTILES_CI_CONFIDENCE,\n",
    "    ):\n",
    "    def add_base_info(r, algorithm, quants):\n",
    "        r[\"decoding\"].extend([algorithm] * len(quants))\n",
    "        r[\"quantiles\"].extend(quants.tolist())\n",
    "    \n",
    "    results = defaultdict(list)\n",
    "    results_lo_rank = defaultdict(list)\n",
    "    results_up_rank = defaultdict(list)\n",
    "    \n",
    "    print(len(decodings), len(files))\n",
    "    # Iterate each decoding algorithm\n",
    "    for dalgo, file in zip(decodings, files):\n",
    "        print(\"Computing quantiles for\", dalgo, \"on\", len(file), \"examples\")\n",
    "        q_intervals = quantile_intervals(len(file), quantiles, conf)\n",
    "        \n",
    "        # Base information\n",
    "        add_base_info(results, dalgo, q_intervals[\"desired_quantiles\"])\n",
    "        add_base_info(results_lo_rank, dalgo, q_intervals[\"desired_quantiles\"])\n",
    "        add_base_info(results_up_rank, dalgo, q_intervals[\"desired_quantiles\"])\n",
    "\n",
    "        # For each property, compute results, lower interval and upper_interval\n",
    "        for prop1 in properties:\n",
    "            val = file[prop1].sort_values().values\n",
    "            \n",
    "            # Measure rank\n",
    "            q_ranks = q_intervals[\"desired_ranks\"].astype(int)\n",
    "            results[prop1].extend(val[q_ranks])\n",
    "            \n",
    "            # Intervals\n",
    "            q_lranks = q_intervals[\"lower_interval_ranks\"].astype(int)\n",
    "            results_lo_rank[prop1].extend(val[q_lranks])\n",
    "            \n",
    "            q_uranks = q_intervals[\"upper_interval_ranks\"].astype(int)\n",
    "            results_up_rank[prop1].extend(val[q_uranks])\n",
    "        \n",
    "    return pd.DataFrame(results), pd.DataFrame(results_lo_rank), pd.DataFrame(results_up_rank)\n",
    "    # return results, results_lo_rank, results_up_rank\n",
    "\n",
    "print(\"Computing quantiles!\")\n",
    "quantiles_results, quantiles_lresults, quantiles_uresults = compute_quantiles(decodings, files)\n",
    "quantiles_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quantiles(quantiles_results, colname: str=\"toxicity\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=150)\n",
    "    sns.scatterplot(quantiles_results, y=\"decoding\", x=colname, hue=\"quantiles\", ax=ax)\n",
    "    plt.legend(title=\"Quantile\", bbox_to_anchor=(1.25, 1), borderaxespad=0)\n",
    "    plt.title(MODEL)\n",
    "    \n",
    "plot_quantiles(quantiles_results, \"toxicity\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8a5f1",
   "metadata": {},
   "source": [
    "### Quantiles with error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2966dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTILE_PALETTE = sns.color_palette(\"colorblind\", n_colors=len(QUANTILES))\n",
    "QUANTILE_COLORS = {q: color for color, q in zip(QUANTILE_PALETTE, QUANTILES)}\n",
    "\n",
    "\n",
    "def plot_quantiles_w_error_bars(quantiles, low_quantiles, up_quantiles, colname=\"toxicity\", qs=QUANTILES, color_by_quantiles=QUANTILE_COLORS, figsize=(10, 10)):\n",
    "    \"\"\"Plot the quantiles and the error bars as given by low_quantiles and up_quantiles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    quantiles: pandas.DataFrame\n",
    "        The data containing the values for different decoding algorithms\n",
    "        and quantiles\n",
    "    \n",
    "    low_quantiles: pandas.DataFrame\n",
    "        The absolute lower bound of the quantiles for different decoding\n",
    "        algorithms,\n",
    "        \n",
    "    up_quantiles: pandas.DataFrame\n",
    "        The absolute upper bound of the quantiles for different decoding\n",
    "        algorithms. We convert it to relative automatically.\n",
    "        \n",
    "    qs: list[float]\n",
    "        The list with the desired quantiles to map. Make sure you\n",
    "        specify quantile values that are present in the data you\n",
    "        provide and for which the color has been defined as well.\n",
    "    \"\"\"\n",
    "    def get_quantile_subset(data, q):\n",
    "        return data[data[\"quantiles\"] == q].copy()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    errs = []\n",
    "    # Iterate for each different value of quantile\n",
    "    for q in qs:\n",
    "        # Pick a common color\n",
    "        qcolor = color_by_quantiles[q]\n",
    "        # Select a slice of the data that is specific to that quantile\n",
    "        qresults = get_quantile_subset(quantiles, q)\n",
    "        # Select the same slice from the lower quantile\n",
    "        qlresults = get_quantile_subset(low_quantiles, q)\n",
    "        # Select the slice from the upper quantile\n",
    "        quresults = get_quantile_subset(up_quantiles, q)\n",
    "        # The size of these slices should be the same\n",
    "        assert len(qresults) == len(qlresults) == len(quresults)\n",
    "        \n",
    "        # Generate some example data\n",
    "        x = qresults[colname].values\n",
    "        y = qresults[\"decoding\"].values\n",
    "        y_err = np.vstack((\n",
    "            qresults[colname].values - qlresults[colname].values,\n",
    "            quresults[colname].values - qresults[colname].values,\n",
    "        ))\n",
    "        # Create the scatterplot with error bars\n",
    "        plt.errorbar(x, y, xerr=y_err, fmt='o', capsize=2, color=qcolor, label=q, alpha=0.7)\n",
    "        errs.append(y_err)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.title(f\"[{MODEL}] {colname}\")\n",
    "    plt.legend(title=\"Quantile\", bbox_to_anchor=(1.15, 1), borderaxespad=0)\n",
    "    \n",
    "    \n",
    "plot_quantiles_w_error_bars(\n",
    "    quantiles=quantiles_results,\n",
    "    low_quantiles=quantiles_lresults,\n",
    "    up_quantiles=quantiles_uresults,\n",
    "    colname=\"toxicity\",\n",
    "    qs=QUANTILES, \n",
    ")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e69695a",
   "metadata": {},
   "source": [
    "# Test that everything is working appropriately\n",
    "__dummy_test = pd.DataFrame({\n",
    "    \"decoding\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\", \"D\", \"D\"],\n",
    "    \"quantiles\": [0.1, 0.5, 0.9, 0.1, 0.5, 0.9] * 2,\n",
    "})\n",
    "__dummy_test_quantiles = __dummy_test.copy()\n",
    "__dummy_test_quantiles[\"property\"] = [0.1, 0.5, 0.9, 0.2, 0.3, 0.8, 0.2, 0.3, 0.8, 0.1, 0.5, 0.9]\n",
    "\n",
    "__dummy_test_lquantiles = __dummy_test.copy()\n",
    "__dummy_test_lquantiles[\"property\"] = [0.05, 0.43, 0.83, 0.1, 0.29, 0.75, 0.1, 0.29, 0.75, 0.05, 0.43, 0.83]\n",
    "\n",
    "__dummy_test_uquantiles = __dummy_test.copy()\n",
    "__dummy_test_uquantiles[\"property\"] = [0.2, 0.55, 0.91, 0.25, 0.35, 0.85, 0.25, 0.35, 0.85, 0.2, 0.55, 0.91]\n",
    "\n",
    "plot_quantiles_w_error_bars(\n",
    "    quantiles=__dummy_test_quantiles,\n",
    "    low_quantiles=__dummy_test_lquantiles,\n",
    "    up_quantiles=__dummy_test_uquantiles,\n",
    "    colname=\"property\",\n",
    "    qs=[0.1, 0.5, 0.9], \n",
    "    figsize=(5,5)\n",
    ")\n",
    "plt.xlim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb61cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb7b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantiles_w_error_bars(\n",
    "    quantiles=quantiles_results,\n",
    "    low_quantiles=quantiles_lresults,\n",
    "    up_quantiles=quantiles_uresults,\n",
    "    colname=\"sequence_log_prob\",\n",
    "    qs=QUANTILES, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodings = quantiles_results[\"decoding\"]\n",
    "quantiles = quantiles_results[\"quantiles\"]\n",
    "results = quantiles_results[\"toxicity\"]\n",
    "lresults = quantiles_lresults[\"toxicity\"]\n",
    "uresults = quantiles_uresults[\"toxicity\"]\n",
    "\n",
    "for d in zip(decodings, quantiles, lresults, results, uresults):\n",
    "    print(d, d[-2] - d[-3], d[-1] - d[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1440fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([1, 3, 2, 4, 5])\n",
    "y_err = np.array([[0.0, 0.2, 0.35, 0.56, 0.78], [0.5, 0.7, 0.4, 0.6, 0.8]])\n",
    "\n",
    "# Create the scatterplot with error bars\n",
    "plt.errorbar(x, y, yerr=y_err, fmt='o')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X-axis label')\n",
    "plt.ylabel('Y-axis label')\n",
    "plt.title('Scatterplot with Custom Error Bars')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3545b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colname: str=\"toxicity\"\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=150)\n",
    "sns.scatterplot(quantiles_results, y=\"decoding\", x=colname, hue=\"quantiles\", ax=ax)\n",
    "plt.legend(title=\"Quantile\", bbox_to_anchor=(1.25, 1), borderaxespad=0)\n",
    "\n",
    "plt.title(MODEL)\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = \"toxicity\"\n",
    "\n",
    "# sns.pointplot(data=quantiles_results, x=colname, y=\"decoding\", join=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c68bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantiles(quantiles_results, \"diversity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0411f4",
   "metadata": {},
   "source": [
    "## Joint distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55303621",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_joints(decodings, files, x=\"toxicity\", y=\"diversity\", bins=(50, 50), rang=((0,1), (0,1))):\n",
    "    for dalgo, file in zip(decodings, files):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(7, 5))\n",
    "        plt.title(f\"[{MODEL}: {dalgo}]\")\n",
    "        ax.hist2d(x=file[x], y=file[y], bins=(100, 20), cmap=plt.cm.Reds, density=True, range=rang)\n",
    "        ax.set_xlabel(x)\n",
    "        ax.set_ylabel(y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753873a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_joints(decodings, files, \"toxicity\", \"diversity\", bins=(100, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0ce31",
   "metadata": {},
   "source": [
    "### Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef06244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot(data_all, by: str, colname):\n",
    "    data_all.groupby(by).count()[colname].plot(kind=\"bar\")\n",
    "    # plt.gca().xaxis.grid(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot(all_files_concat[all_files_concat[\"toxicity\"] > 0.5], \"decoding\", \"toxicity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e418c",
   "metadata": {},
   "source": [
    "## Greedy-like sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.text import Text\n",
    "\n",
    "# Console for printing with nice colors :)\n",
    "console = Console(width=80)\n",
    "\n",
    "ALL_COLORS = {}\n",
    "for colors_dict in DEFAULT_COLORS.values():\n",
    "    for k, v in colors_dict.items():\n",
    "        ALL_COLORS[k] = v\n",
    "        \n",
    "def pprint(text, model_score, decoding, counts=0):\n",
    "    msg  = f\"\\n\\n({decoding}) {model_score:.2%} Toxicity (generated {counts} times /15000)\\nText: [cyan]'{text}'[/cyan]\"\n",
    "    console.print(msg)\n",
    "    \n",
    "    \n",
    "def pprint_df(df: pd.DataFrame, colname: str, n=None):\n",
    "    df_ndup = df.drop_duplicates(\"sequence\").reset_index(drop=True).copy()\n",
    "\n",
    "    for i, row in df_ndup.iterrows():\n",
    "        n_times = (df[\"sequence\"] == row[\"sequence\"]).sum()\n",
    "        pprint(row[\"sequence\"], row[colname], row[\"decoding\"], n_times)\n",
    "        \n",
    "        if n is not None and i > n:\n",
    "            print(i, n)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_greedy = files[decodings.index(\"temperature_0.1\")].sort_values(\"toxicity\", ascending=False)\n",
    "print(\"Temperature=0.1: |S| =\", temp_greedy['sequence'].nunique())\n",
    "\n",
    "top_p_greedy  = files[decodings.index(\"top_p_0.1\")].sort_values(\"toxicity\", ascending=False)\n",
    "print(\"Top-p=0.1: |S| =\", top_p_greedy['sequence'].nunique())\n",
    "\n",
    "top_k_greedy  = files[decodings.index(\"top_k_2\")].sort_values(\"toxicity\", ascending=False)\n",
    "print(\"Top-k=2: |S| =\", top_k_greedy['sequence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint_df(top_p_greedy, \"toxicity\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d480b842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint_df(temp_greedy, \"toxicity\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bc144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint_df(top_k_greedy, \"toxicity\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c2c9e",
   "metadata": {},
   "source": [
    "# Worst case analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510dc5b",
   "metadata": {},
   "source": [
    "### Toxicity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_files = [f.sort_values(\"toxicity\", ascending=False).head(150) for f in files]\n",
    "bottom_files_concat = pd.concat(bottom_files, axis=0)\n",
    "bottom_quantiles = compute_quantiles(decodings, bottom_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e41aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantiles(bottom_quantiles, \"toxicity\")\n",
    "plot_quantiles(bottom_quantiles, \"diversity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc249e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_joints(decodings, bottom_files, \"toxicity\", \"diversity\", bins=(50, 50), rang=((0,1), (0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5768ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
