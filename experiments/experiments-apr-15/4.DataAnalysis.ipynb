{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/extra/ucinlp1/cbelem/experiments-apr-15/toxicity_results/\"\n",
    "\n",
    "TARGET_WORDS = [\"buddhist\", \"christian\", \"jewish\", \"muslim\"]\n",
    "SAMPLING = [\"multinomial\", \"temperature\", \"top-k\", \"top-p\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6dc35",
   "metadata": {},
   "source": [
    "## Load Data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = f\"{BASE_DIR}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c697244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these results include the toxicity of the whole sequence\n",
    "DATA_BY_TARGET = {target_word: pd.read_csv(f\"{DATA_DIR}/{target_word}.csv\", index_col=0) for target_word in TARGET_WORDS}\n",
    "print({t: len(d) for t, d in DATA_BY_TARGET.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650e516",
   "metadata": {},
   "source": [
    "## Load model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = f\"{BASE_DIR}/models/EleutherAI__pythia-70m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6976669",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BY_TARGET = {}\n",
    "\n",
    "for target in TARGET_WORDS:\n",
    "    target_filenames = [f\"{target}_{s}\" for s in SAMPLING]\n",
    "    target_data = [pd.read_csv(f\"{MODEL_DIR}/{f}.csv\", index_col=0) for f in target_filenames]\n",
    "    target_data = pd.concat(target_data).reset_index(drop=True)\n",
    "    \n",
    "    MODEL_BY_TARGET[target] = target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b97194",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BY_TARGET[\"muslim\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c49e9",
   "metadata": {},
   "source": [
    "## Compute the length\n",
    "\n",
    "Add an additional property for the text. For simplicity we will measure the length (in characters of the generated text). Since the prefix in the data and generated sequences is the same, the actual difference between the two distributions will be due to the generated text wrt to the continuation.\n",
    "\n",
    "There is, however, a bias since we have not completely removed the punctuation. In a future analysis, we may compute the number of characters until the first or second punctuation.\n",
    "\n",
    "\n",
    "More important than implementing it because \"it's easy\" is whether **we have a use case for it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa2270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b9708a5",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c2431a",
   "metadata": {},
   "source": [
    "## Cumulative Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4dd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histplot(target: str, attr: str, sampling: str, data_dict=DATA_BY_TARGET, model_dict=MODEL_BY_TARGET, ax=None):\n",
    "    kwargs = {\"binrange\": (0, 1), \"bins\": 30, \"element\": \"step\", \"alpha\": 0.5, \"cumulative\": True}#, \"stat\": \"probability\"}\n",
    "    \n",
    "    if ax is not None:\n",
    "        kwargs.update(ax=ax)\n",
    "    \n",
    "    # 1. select model by target\n",
    "    model_by_target = model_dict[target]\n",
    "    model_by_target = model_by_target.rename({\"prefix\": \"min_prefix\"}, axis=1)\n",
    "    print(\"model_by_target\", len(model_by_target))\n",
    "    # 2. select data by target and by attribute\n",
    "    data_by_target = data_dict[target]\n",
    "    data_by_target_by_attr = data_by_target[data_by_target[\"attribute\"] == attr]\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    # 3. select model by attribute (implicitly via min_prefix)\n",
    "    mask = model_by_target[\"min_prefix\"].isin(data_by_target_by_attr[\"min_prefix\"])\n",
    "    model_by_target_by_attr = model_by_target[mask]\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr))\n",
    "\n",
    "    # 4. select data by prefixes in model\n",
    "    mask = data_by_target_by_attr[\"min_prefix\"].isin(model_by_target_by_attr[\"min_prefix\"])\n",
    "    data_by_target_by_attr = data_by_target_by_attr[mask]\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    # 5. select specific sampling\n",
    "    sampling_mask = model_by_target[\"sampling\"] == sampling\n",
    "    model_by_target_by_attr = model_by_target_by_attr[sampling_mask]\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr), len(model_by_target_by_attr) / model_by_target_by_attr[\"sampling_kwargs\"].nunique())\n",
    "\n",
    "    # 6. Average model's results\n",
    "    model_by_target_by_attr = model_by_target_by_attr[[\"min_prefix\", \"sampling_kwargs\", \"toxicity\"]].groupby([\"min_prefix\", \"sampling_kwargs\"]).mean()\n",
    "    model_by_target_by_attr = model_by_target_by_attr.reset_index()\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr))\n",
    "    \n",
    "    # 7. Average data's results\n",
    "    data_by_target_by_attr = data_by_target_by_attr[[\"min_prefix\", \"toxicity\"]].groupby([\"min_prefix\"]).mean()\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    sns.histplot(data=data_by_target_by_attr, x=\"toxicity\", color=\"black\", ls=\"--\", fill=False, **kwargs)\n",
    "    g = sns.histplot(data=model_by_target_by_attr, x=\"toxicity\", hue=\"sampling_kwargs\", **kwargs)\n",
    "    \n",
    "    if ax:\n",
    "        # h, l = ax.get_legend_handles_labels()\n",
    "        ax.set_title(f\"[{target}, {attr}]: {sampling}\")\n",
    "        # h, l = ax.get_legend_handles_labels()\n",
    "\n",
    "        # ax.legend(h, l, loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=2)\n",
    "    else:\n",
    "        sns.move_legend(g, \"upper left\", bbox_to_anchor=(1.01, 0.5))\n",
    "        plt.title(f\"[{target}, {attr}]: {sampling}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e86266",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTE_WORDS = [\"happy\", \"sad\", \"calm\", \"angry\", \"terror\", \"peace\", \"dead\", \"death\", \"great\", \"good\", \"bad\", \"terrible\", \"positive\", \"negative\", \"skill\", \"food\"]\n",
    "ATTRIBUTE_WORDS = sorted(ATTRIBUTE_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66098f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for attr in ATTRIBUTE_WORDS:\n",
    "    print(\"\\n\"*5)\n",
    "    print(attr)\n",
    "    print(\"\\n\")\n",
    "    for target in TARGET_WORDS:\n",
    "        fig, axes = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(30, 5))\n",
    "        plot_histplot(target, attr, \"multinomial\", ax=axes[0])\n",
    "        plot_histplot(target, attr, \"temperature\", ax=axes[1])\n",
    "        plot_histplot(target, attr, \"top-p\", ax=axes[2])\n",
    "        plot_histplot(target, attr, \"top-k\", ax=axes[3])\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14fcd1",
   "metadata": {},
   "source": [
    "## ScatterPlot - Correlation between data toxicity and model toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatterplot(target: str, attr: str, sampling: str, data_dict=DATA_BY_TARGET, model_dict=MODEL_BY_TARGET, ax=None):\n",
    "    kwargs = {} \n",
    "\n",
    "    if ax is not None:\n",
    "        kwargs.update(ax=ax)\n",
    "    \n",
    "    # 1. select model by target\n",
    "    model_by_target = model_dict[target]\n",
    "    model_by_target = model_by_target.rename({\"prefix\": \"min_prefix\"}, axis=1)\n",
    "    print(\"model_by_target\", len(model_by_target))\n",
    "    # 2. select data by target and by attribute\n",
    "    data_by_target = data_dict[target]\n",
    "    data_by_target_by_attr = data_by_target[data_by_target[\"attribute\"] == attr]\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    # 3. select model by attribute (implicitly via min_prefix)\n",
    "    mask = model_by_target[\"min_prefix\"].isin(data_by_target_by_attr[\"min_prefix\"])\n",
    "    model_by_target_by_attr = model_by_target[mask]\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr))\n",
    "\n",
    "    # 4. select data by prefixes in model\n",
    "    mask = data_by_target_by_attr[\"min_prefix\"].isin(model_by_target_by_attr[\"min_prefix\"])\n",
    "    data_by_target_by_attr = data_by_target_by_attr[mask]\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    # 5. select specific sampling\n",
    "    sampling_mask = model_by_target[\"sampling\"] == sampling\n",
    "    model_by_target_by_attr = model_by_target_by_attr[sampling_mask]\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr), len(model_by_target_by_attr) / model_by_target_by_attr[\"sampling_kwargs\"].nunique())\n",
    "\n",
    "    # 6.0. sort data\n",
    "    model_by_target_by_attr = model_by_target_by_attr.sort_values(\"min_prefix\")\n",
    "    data_by_target_by_attr = data_by_target_by_attr.sort_values(\"min_prefix\")\n",
    "    \n",
    "    # 6. Average model's results\n",
    "    model_by_target_by_attr_std = model_by_target_by_attr[[\"min_prefix\", \"sampling_kwargs\", \"toxicity\"]].groupby([\"min_prefix\", \"sampling_kwargs\"]).std()\n",
    "\n",
    "    model_by_target_by_attr = model_by_target_by_attr[[\"min_prefix\", \"sampling_kwargs\", \"toxicity\"]].groupby([\"min_prefix\", \"sampling_kwargs\"]).mean()\n",
    "    model_by_target_by_attr = model_by_target_by_attr.reset_index()\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr))\n",
    "    \n",
    "    # 7. Average data's results\n",
    "    data_by_target_by_attr_std = data_by_target_by_attr[[\"min_prefix\", \"toxicity\"]].groupby([\"min_prefix\"]).std()\n",
    "    data_by_target_by_attr = data_by_target_by_attr[[\"min_prefix\", \"toxicity\"]].groupby([\"min_prefix\"]).mean()\n",
    "    data_by_target_by_attr = data_by_target_by_attr.reset_index()\n",
    "\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))    \n",
    "    \n",
    "    for sampl_kwargs in sorted(model_by_target_by_attr[\"sampling_kwargs\"].unique()):\n",
    "        model_data_by_sampl = model_by_target_by_attr[model_by_target_by_attr[\"sampling_kwargs\"] == sampl_kwargs]\n",
    "        assert np.array_equal(data_by_target_by_attr[\"min_prefix\"], model_data_by_sampl[\"min_prefix\"])\n",
    "        g = sns.regplot(x=data_by_target_by_attr[\"toxicity\"], y=model_data_by_sampl[\"toxicity\"], label=sampl_kwargs)\n",
    "        #    assert np.array_equal(data_by_target_by_attr_std.index, model_by_target_by_attr_std.index)\n",
    "\n",
    "    if ax:\n",
    "        # h, l = ax.get_legend_handles_labels()\n",
    "        ax.set_title(f\"[{target}, {attr}]: {sampling}\")\n",
    "        # ax.legend(h, l, loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=2)\n",
    "    else:\n",
    "        # sns.move_legend(g, \"upper left\", bbox_to_anchor=(1.01, 0.5))\n",
    "        plt.title(f\"[{target}, {attr}]: {sampling}\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Data Toxicity\")\n",
    "        plt.ylabel(\"Model Toxcity\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84633665",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# todo add iteration by attr word\n",
    "for target in TARGET_WORDS:\n",
    "    plot_scatterplot(target, \"terror\", \"multinomial\")\n",
    "    plot_scatterplot(target, \"terror\", \"temperature\")\n",
    "    plot_scatterplot(target, \"terror\", \"top-p\")\n",
    "    plot_scatterplot(target, \"terror\", \"top-k\")\n",
    "    print(\"\\n\\n\\n\\n =========================== \\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ac998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(target: str, attr: str, sampling: str, data_dict=DATA_BY_TARGET, model_dict=MODEL_BY_TARGET, ax=None, figsize=(10, 5)):\n",
    "    kwargs = {} \n",
    "\n",
    "    if ax is not None:\n",
    "        kwargs.update(ax=ax)\n",
    "    else:\n",
    "        plt.figure(figsize=figsize)\n",
    "    # 1. select model by target\n",
    "    model_by_target = model_dict[target]\n",
    "    model_by_target = model_by_target.rename({\"prefix\": \"min_prefix\"}, axis=1)\n",
    "    print(\"model_by_target\", len(model_by_target))\n",
    "    # 2. select data by target and by attribute\n",
    "    data_by_target = data_dict[target]\n",
    "    data_by_target_by_attr = data_by_target[data_by_target[\"attribute\"] == attr]\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    # 3. select model by attribute (implicitly via min_prefix)\n",
    "    mask = model_by_target[\"min_prefix\"].isin(data_by_target_by_attr[\"min_prefix\"])\n",
    "    model_by_target_by_attr = model_by_target[mask]\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr))\n",
    "\n",
    "    # 4. select data by prefixes in model\n",
    "    mask = data_by_target_by_attr[\"min_prefix\"].isin(model_by_target_by_attr[\"min_prefix\"])\n",
    "    data_by_target_by_attr = data_by_target_by_attr[mask]\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    # 5. select specific sampling\n",
    "    sampling_mask = model_by_target[\"sampling\"] == sampling\n",
    "    model_by_target_by_attr = model_by_target_by_attr[sampling_mask]\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr), len(model_by_target_by_attr) / model_by_target_by_attr[\"sampling_kwargs\"].nunique())\n",
    "\n",
    "    # 6.0. sort data\n",
    "    model_by_target_by_attr = model_by_target_by_attr.sort_values(\"min_prefix\")\n",
    "    data_by_target_by_attr = data_by_target_by_attr.sort_values(\"min_prefix\")\n",
    "    \n",
    "    # 6. Average model's results\n",
    "    model_by_target_by_attr_std = model_by_target_by_attr[[\"min_prefix\", \"sampling_kwargs\", \"toxicity\"]].groupby([\"min_prefix\", \"sampling_kwargs\"]).std()\n",
    "\n",
    "    model_by_target_by_attr = model_by_target_by_attr[[\"min_prefix\", \"sampling_kwargs\", \"toxicity\"]].groupby([\"min_prefix\", \"sampling_kwargs\"]).mean()\n",
    "    model_by_target_by_attr = model_by_target_by_attr.reset_index()\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr))\n",
    "    \n",
    "    # 7. Average data's results\n",
    "    data_by_target_by_attr_std = data_by_target_by_attr[[\"min_prefix\", \"toxicity\"]].groupby([\"min_prefix\"]).std()\n",
    "    data_by_target_by_attr = data_by_target_by_attr[[\"min_prefix\", \"toxicity\"]].groupby([\"min_prefix\"]).mean()\n",
    "    data_by_target_by_attr = data_by_target_by_attr.reset_index()\n",
    "    data_by_target_by_attr[\"toxicity_bins\"] = pd.cut(data_by_target_by_attr[\"toxicity\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "    \n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))    \n",
    "    g = sns.boxplot(x=data_by_target_by_attr[\"toxicity_bins\"],\n",
    "                    y=model_by_target_by_attr[\"toxicity\"],\n",
    "                    hue=model_by_target_by_attr[\"sampling_kwargs\"], **kwargs\n",
    "    )\n",
    "\n",
    "    if ax:\n",
    "        # h, l = ax.get_legend_handles_labels()\n",
    "        ax.set_title(f\"[{target}, {attr}]: {sampling}\")\n",
    "        # ax.legend(h, l, loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=2)\n",
    "    else:\n",
    "        sns.move_legend(g, loc=\"upper left\", bbox_to_anchor=(1.01, 1.0))\n",
    "        plt.title(f\"[{target}, {attr}]: {sampling}\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Data Toxicity\")\n",
    "        plt.ylabel(\"Model Toxcity\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8aae61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for target in TARGET_WORDS:\n",
    "    fig, axes = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(30, 5))\n",
    "    plot_box(target, \"terror\", \"multinomial\", ax=axes[0])\n",
    "    plot_box(target, \"terror\", \"temperature\", ax=axes[1])\n",
    "    plot_box(target, \"terror\", \"top-p\", ax=axes[2])\n",
    "    plot_box(target, \"terror\", \"top-k\", ax=axes[3])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\\n\\n =========================== \\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3192d",
   "metadata": {},
   "source": [
    "### KDE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aeb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kdeplot(target: str, attr: str, sampling: str, data_dict=DATA_BY_TARGET, model_dict=MODEL_BY_TARGET, ax=None):\n",
    "    kwargs = {}\n",
    "    \n",
    "    if ax is not None:\n",
    "        kwargs.update(ax=ax)\n",
    "    \n",
    "    # Select data by target and by attribute\n",
    "    data_by_target = data_dict[target]\n",
    "    data_by_target_by_attr = data_by_target[data_by_target[\"attribute\"] == attr]\n",
    "\n",
    "    # select model by target\n",
    "    model_by_target = model_dict[target]\n",
    "    model_by_target = model_by_target.rename({\"prefix\": \"min_prefix\"}, axis=1)\n",
    "\n",
    "    # select model by attribute (implicitly via min_prefix)\n",
    "    mask = model_by_target[\"min_prefix\"].isin(data_by_target_by_attr[\"min_prefix\"])\n",
    "    \n",
    "    # select specific sampling\n",
    "    sampling_mask = model_by_target[\"sampling\"] == sampling\n",
    "    model_by_target_by_attr = model_by_target[mask & sampling_mask]\n",
    "    \n",
    "    model_mult_by_target_by_attr = model_by_target[mask & (model_by_target[\"sampling\"] == \"multinomial\")]\n",
    "    \n",
    "    # average model's results\n",
    "    # model_by_target_by_attr = model_by_target_by_attr.groupby([\"min_prefix\", \"sampling_kwargs\"]).mean()\n",
    "    # model_by_target_by_attr = model_by_target_by_attr.reset_index()\n",
    "\n",
    "    sns.kdeplot(data=data_by_target_by_attr, x=\"toxicity\", color=\"black\", common_norm=False, cut=0, **kwargs)\n",
    "    ax.axvline(data_by_target_by_attr[\"toxicity\"].mean(), color=\"black\", ls=\"--\")\n",
    "    \n",
    "    sns.kdeplot(data=model_by_target_by_attr, x=\"toxicity\", hue=\"sampling_kwargs\", common_norm=False, cut=0, alpha=0.5, **kwargs)\n",
    "    for sampl in model_by_target_by_attr[\"sampling_kwargs\"].unique():\n",
    "        sampl_data = model_by_target_by_attr[model_by_target_by_attr[\"sampling_kwargs\"] == sampl]\n",
    "        ax.axvline(sampl_data[\"toxicity\"].mean(), ls=\"--\", label=sampl)\n",
    "    \n",
    "    \n",
    "    # Multinomial sampling\n",
    "    sns.kdeplot(data=model_mult_by_target_by_attr, x=\"toxicity\", color=\"purple\", common_norm=False, cut=0, **kwargs)\n",
    "    ax.axvline(model_mult_by_target_by_attr[\"toxicity\"].mean(), color=\"purple\", ls=\"--\")\n",
    "    \n",
    "    \n",
    "    if ax is not None:\n",
    "        ax.set_title(f\"[{target}, {attr}]: {sampling}\")\n",
    "    else:\n",
    "        plt.set_title(f\"[{target}, {attr}]: {sampling}\")\n",
    "\n",
    "    \n",
    "fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(30, 5))\n",
    "plot_kdeplot(\"christian\", \"angry\", \"temperature\", ax=axes[0])\n",
    "plot_kdeplot(\"christian\", \"angry\", \"top-p\", ax=axes[1])\n",
    "plot_kdeplot(\"christian\", \"angry\", \"top-k\", ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in ATTRIBUTE_WORDS:\n",
    "    for target in TARGET_WORDS:\n",
    "        fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(30, 5))\n",
    "        plot_kdeplot(target, attr, \"temperature\", ax=axes[0])\n",
    "        plot_kdeplot(target, attr, \"top-p\", ax=axes[1])\n",
    "        plot_kdeplot(target, attr, \"top-k\", ax=axes[2])\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d29ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - Analysis of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb055c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45cd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "buddhist_terror = get_data(\"buddhist\", \"terror\")\n",
    "for i, row in buddhist_terror.model.sort_values(\"toxicity\", ascending=False).head(60).iterrows():\n",
    "    generation = row[\"sequence\"][len(row[\"min_prefix\"]):]\n",
    "    print()\n",
    "    print(row[\"toxicity\"], \"\\n--> \", row[\"sampling_kwargs\"], \"\\n--> prefix:\", row[\"min_prefix\"], \"\\n--> generation:\", generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "muslim_angry = get_data(\"muslim\", \"angry\")\n",
    "muslim_happy = get_data(\"muslim\", \"happy\")\n",
    "muslim_terror = get_data(\"muslim\", \"terror\")\n",
    "muslim_food = get_data(\"muslim\", \"food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(30, 5))\n",
    "plot_kdeplot(\"muslim\", \"terror\", \"multinomial\", ax=axes[0])\n",
    "plot_kdeplot(\"muslim\", \"terror\", \"temperature\", ax=axes[1])\n",
    "plot_kdeplot(\"muslim\", \"terror\", \"top-p\", ax=axes[2])\n",
    "plot_kdeplot(\"muslim\", \"terror\", \"top-k\", ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5271d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44deda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c1b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93899486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298960c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688d018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a541d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(target: str, attr: str, sampling: str=None, data_dict=DATA_BY_TARGET, model_dict=MODEL_BY_TARGET):\n",
    "    # 1. select model by target\n",
    "    model_by_target = model_dict[target]\n",
    "    model_by_target = model_by_target.rename({\"prefix\": \"min_prefix\"}, axis=1)\n",
    "    print(\"model_by_target\", len(model_by_target))\n",
    "    # 2. select data by target and by attribute\n",
    "    data_by_target = data_dict[target]\n",
    "    data_by_target_by_attr = data_by_target[data_by_target[\"attribute\"] == attr]\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    # 3. select model by attribute (implicitly via min_prefix)\n",
    "    mask = model_by_target[\"min_prefix\"].isin(data_by_target_by_attr[\"min_prefix\"])\n",
    "    model_by_target_by_attr = model_by_target[mask]\n",
    "    print(\"model_by_target_by_attr\", len(model_by_target_by_attr))\n",
    "\n",
    "    # 4. select data by prefixes in model\n",
    "    mask = data_by_target_by_attr[\"min_prefix\"].isin(model_by_target_by_attr[\"min_prefix\"])\n",
    "    data_by_target_by_attr = data_by_target_by_attr[mask]\n",
    "    print(\"data_by_target_by_attr\", len(data_by_target_by_attr))\n",
    "\n",
    "    # 5. select specific sampling\n",
    "    if sampling is not None:\n",
    "        sampling_mask = model_by_target[\"sampling\"] == sampling\n",
    "        model_by_target_by_attr = model_by_target_by_attr[sampling_mask]\n",
    "        print(\"model_by_target_by_attr\", len(model_by_target_by_attr), len(model_by_target_by_attr) / model_by_target_by_attr[\"sampling_kwargs\"].nunique())\n",
    "\n",
    "    class Result:\n",
    "        pass\n",
    "\n",
    "    result = Result()\n",
    "    result.data = data_by_target_by_attr\n",
    "    result.model = model_by_target_by_attr\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4303412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6ae37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183e4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95480a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d8bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668508d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc03d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_target_by_attr[\"toxicity_bins\"] = pd.cut(data_by_target_by_attr[\"toxicity\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa22e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0d462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542af9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_target_by_attr[\"toxicity_bins\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf76078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec44f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4668be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375a322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55942fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(30, 5))\n",
    "plot_kdeplot(\"muslim\", \"terror\", \"multinomial\", ax=axes[0])\n",
    "plot_kdeplot(\"muslim\", \"terror\", \"temperature\", ax=axes[1])\n",
    "plot_kdeplot(\"muslim\", \"terror\", \"top-p\", ax=axes[2])\n",
    "plot_kdeplot(\"muslim\", \"terror\", \"top-k\", ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7656d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(30, 5))\n",
    "plot_kdeplot(\"christian\", \"terror\", \"multinomial\", ax=axes[0])\n",
    "plot_kdeplot(\"christian\", \"terror\", \"temperature\", ax=axes[1])\n",
    "plot_kdeplot(\"christian\", \"terror\", \"top-p\", ax=axes[2])\n",
    "plot_kdeplot(\"christian\", \"terror\", \"top-k\", ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(30, 5))\n",
    "plot_kdeplot(\"christian\", \"happy\", \"multinomial\", ax=axes[0])\n",
    "plot_kdeplot(\"christian\", \"happy\", \"temperature\", ax=axes[1])\n",
    "plot_kdeplot(\"christian\", \"happy\", \"top-p\", ax=axes[2])\n",
    "plot_kdeplot(\"christian\", \"happy\", \"top-k\", ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d4c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d042351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_by_target_by_attr.groupby([\"sampling\", \"sampling_kwargs\"]).mean().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ab4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35aabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dca1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the sequences used to seed the model sequences\n",
    "# ------------------------------------------------------------\n",
    "# (if we have duplicate min_prefixes, we will pick one)\n",
    "# ------------------------------------------------------------\n",
    "data_by_target_seq_sampled = data_by_target[\"min_prefix\"].isin(model_by_target[\"min_prefix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_by_target), len(data_by_target_seq_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# 1. Plot data distribution of toxicity scores per (target, attribute)\n",
    "# 2. Plot model distribution for decoding algorithm X toxicity scores per (target, attribute)\n",
    "#     - Pick decoding algorithm\n",
    "#     - Match prefix w/ attributes\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "attr = \"happy\"\n",
    "data_by_target_by_attr = data_by_target[data_by_target[\"attribute\"] == attr]\n",
    "\n",
    "sns.kdeplot(data=data_by_target_by_attr, x=\"toxicity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_by_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data_by_target_by_attr, x=\"toxicity\", element=\"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc959d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b2e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53337590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ac4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a7f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbbb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121ff69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = model_by_target.set_index(\"min_prefix\").copy()\n",
    "t2 = data_by_target.set_index(\"min_prefix\").copy()\n",
    "\n",
    "t = t1.join(t2, how=\"inner\", lsuffix=\"_model\", rsuffix=\"_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2[t2.index.isin(t1.index)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
